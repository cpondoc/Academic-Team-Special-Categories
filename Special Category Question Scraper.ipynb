{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special Category Question Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses BeautifulSoup to try and parse through Quizlet and find good questions to ask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used to make a request to the URL, parse through the HTML, and save the information as a .txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Links for Quizlet Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a key word, this function will create a URL based on the key word and extract all of the possible sets using that key word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(category):\n",
    "    \n",
    "    # Empty array to hold link strings\n",
    "    links_strings = []\n",
    "    \n",
    "    # Define the URL\n",
    "    URL = \"https://quizlet.com/subject/\" + category + \"/\"\n",
    "    \n",
    "    # Make a request for the URL\n",
    "    r = requests.get(URL) \n",
    "    \n",
    "    # Make a BeautifulSoup object to parse the HTML\n",
    "    soup = BeautifulSoup(r.content, 'html5lib') \n",
    "    \n",
    "    # Parse through all of the links\n",
    "    for link in soup.find_all('a'):\n",
    "        \n",
    "        # Get the string of a link\n",
    "        link_string = link.get('href')\n",
    "        \n",
    "        # Check if a string is a valid URL\n",
    "        if (link_string[0] != \"/\" and \"quizlet.com/\" in link_string):\n",
    "            \n",
    "            # Append to overall link strings\n",
    "            link_strings.append(link_string)\n",
    "            \n",
    "    return link_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Questions from the Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets the questions from the links and appends them to a .txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_questions(topic, link_strings):\n",
    "    \n",
    "    # Opens up a new file with the topic name\n",
    "    file1 = open(\"questions/\" + topic + \".txt\",\"w\") \n",
    "    \n",
    "    # For each link in the array of links\n",
    "    for link in link_strings:\n",
    "        \n",
    "        # Make a new request for the link\n",
    "        r = requests.get(link)\n",
    "        \n",
    "        # Make a BeautifulSoup object to parse the HTML\n",
    "        soup = BeautifulSoup(r.content, 'html5lib') \n",
    "        \n",
    "        # Parse through all of the a tags in the links\n",
    "        for link in soup.find_all('a'):\n",
    "            \n",
    "            # Check to see what the classes of the a tags are\n",
    "            link_class = link.get('class')[0]\n",
    "            \n",
    "            # If the tag is a term\n",
    "            if (link_class == \"SetPageTerm-wordText\"):\n",
    "                \n",
    "                # Get the text of the term\n",
    "                span_text = str(link.contents)\n",
    "                \n",
    "                # Take out any extra HTML tags\n",
    "                span_text = span_text.replace(\"<br/>\", \"\")\n",
    "                \n",
    "                # Write the term to the text file\n",
    "                file1.write(\"Term: \" + ((span_text)[44:len(span_text) -8]) + \"\\n\")\n",
    "                \n",
    "            # If the tag is a definition\n",
    "            elif (link_class == \"SetPageTerm-definitionText\"):\n",
    "                \n",
    "                # Get the text of the definition\n",
    "                span_text = str(link.contents)\n",
    "                \n",
    "                # Take out any extra HTML tags\n",
    "                span_text = span_text.replace(\"<br/>\", \"\")\n",
    "                \n",
    "                # Write the definition to the text file\n",
    "                file1.write(\"Definition: \" + ((span_text)[44:len(span_text) -8])  + \"\\n\\n\")\n",
    "\n",
    "    # Close the file\n",
    "    file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests all necessary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_categories = [\"star-wars\", \"world-war-ii\", \"shakespeare's-works\", \"physics\"]\n",
    "\n",
    "for category in special_categories:\n",
    "    \n",
    "    # Create an empty array of links\n",
    "    link_strings = []\n",
    "    \n",
    "    # Get all of the links corresponding to a certain category\n",
    "    link_strings = get_links(category)\n",
    "    \n",
    "    # Create the questions for the category\n",
    "    create_questions(category, link_strings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
